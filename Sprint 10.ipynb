{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Selection of Oil Well Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The goal of this project is to determine the optimal sites for the construction of 200 new oil wells by examining three oil exploration zones. We assessed the volume of reserves in each location using a linear regression model, and we used the projected reserves to assess each region's risk and profitability. After evaluating possible risks and returns using bootstrapping techniques, the project suggests exploiting the area with the highest average profit and tolerable risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "**Selection of the Top 200 Oil Wells per Region**  \n",
    "The goal is to select the top 200 wells with the highest predicted reserves in each region. This will be done using the predicted values from a linear regression model, ensuring that the wells with the greatest production potential are prioritized for profitability analysis.\n",
    "\n",
    "**Calculation of Potential Profit from the Selected 200 Wells**  \n",
    "Once the top 200 wells are selected for each region, the potential profit will be calculated by multiplying the predicted reserves by the unit revenue. This will help assess the financial viability of exploiting the selected wells in each region.\n",
    "\n",
    "**Risk and Profit Analysis Using Bootstrapping**  \n",
    "Using the predictions for the top 200 wells, a bootstrapping analysis will be conducted with 1000 samples to estimate the profit distribution. This will include calculating the average profit, 95% confidence interval, and loss risk percentage, helping to identify the region with the best potential for profitable and low-risk oil well exploitation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Download and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Model Evaluation and Metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats as st\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Data Resampling\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load geographical datasets from CSV files\n",
    "df = pd.read_csv('geo_data_0.csv')\n",
    "df_1 = pd.read_csv('geo_data_1.csv')\n",
    "df_2 = pd.read_csv('geo_data_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Region 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General Information\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "========================================\n",
      "Data Overview\n",
      "\n",
      "      id        f0        f1        f2     product\n",
      "0  txEyH  0.705745 -0.497823  1.221170  105.280062\n",
      "1  2acmU  1.334711 -0.340164  4.365080   73.037750\n",
      "2  409Wp  1.022732  0.151990  1.419926   85.265647\n",
      "3  iJLyR -0.032172  0.139033  2.978566  168.620776\n",
      "4  Xdl7t  1.988431  0.155413  4.751769  154.036647\n",
      "==================================================\n",
      "Null Values\n",
      "\n",
      "id         0\n",
      "f0         0\n",
      "f1         0\n",
      "f2         0\n",
      "product    0\n",
      "dtype: int64\n",
      "========================================\n",
      "Duplicate Values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id         0\n",
       "f0         0\n",
       "f1         0\n",
       "f2         0\n",
       "product    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('General Information')\n",
    "print()\n",
    "df.info()  # General information about the dataset\n",
    "print('='*40)\n",
    "print('Data Overview')\n",
    "print()\n",
    "print(df.head())  # Columns of the dataset\n",
    "print('='*50)\n",
    "print('Null Values')\n",
    "print()\n",
    "print(df.isnull().sum())  # Count of null values\n",
    "print('='*40)\n",
    "print('Duplicate Values')  # Count of duplicate values\n",
    "df.isna().sum()  # Count of missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General Information\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "========================================\n",
      "Data Overview\n",
      "\n",
      "      id         f0         f1        f2     product\n",
      "0  kBEdx -15.001348  -8.276000 -0.005876    3.179103\n",
      "1  62mP7  14.272088  -3.475083  0.999183   26.953261\n",
      "2  vyE1P   6.263187  -5.948386  5.001160  134.766305\n",
      "3  KcrkZ -13.081196 -11.506057  4.999415  137.945408\n",
      "4  AHL4O  12.702195  -8.147433  5.004363  134.766305\n",
      "==================================================\n",
      "Null Values\n",
      "\n",
      "id         0\n",
      "f0         0\n",
      "f1         0\n",
      "f2         0\n",
      "product    0\n",
      "dtype: int64\n",
      "========================================\n",
      "Duplicate Values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id         0\n",
       "f0         0\n",
       "f1         0\n",
       "f2         0\n",
       "product    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('General Information')\n",
    "print()\n",
    "df_1.info()  # General information about the dataset\n",
    "print('='*40)\n",
    "print('Data Overview')\n",
    "print()\n",
    "print(df_1.head())  # Columns of the dataset # CORRECTED BY REVIEWER\n",
    "print('='*50)\n",
    "print('Null Values')\n",
    "print()\n",
    "print(df_1.isnull().sum())  # Count of null values\n",
    "print('='*40)\n",
    "print('Duplicate Values')  # Count of duplicate values\n",
    "df_1.isna().sum()  # Count of missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General Information\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "========================================\n",
      "Data Overview\n",
      "\n",
      "      id        f0        f1        f2     product\n",
      "0  fwXo0 -1.146987  0.963328 -0.828965   27.758673\n",
      "1  WJtFt  0.262778  0.269839 -2.530187   56.069697\n",
      "2  ovLUW  0.194587  0.289035 -5.586433   62.871910\n",
      "3  q6cA6  2.236060 -0.553760  0.930038  114.572842\n",
      "4  WPMUX -0.515993  1.716266  5.899011  149.600746\n",
      "==================================================\n",
      "Null Values\n",
      "\n",
      "id         0\n",
      "f0         0\n",
      "f1         0\n",
      "f2         0\n",
      "product    0\n",
      "dtype: int64\n",
      "========================================\n",
      "Duplicate Values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id         0\n",
       "f0         0\n",
       "f1         0\n",
       "f2         0\n",
       "product    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('General Information')\n",
    "print()\n",
    "df_2.info()  # General information about the dataset\n",
    "print('='*40)\n",
    "print('Data Overview')\n",
    "print()\n",
    "print(df_2.head())  # Columns of the dataset\n",
    "print('='*50)\n",
    "print('Null Values')\n",
    "print()\n",
    "print(df_2.isnull().sum())  # Count of null values\n",
    "print('='*40)\n",
    "print('Duplicate Values')  # Count of duplicate values\n",
    "df_2.isna().sum()  # Count of missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into features and targets\n",
    "\n",
    "features = df.drop(['id', 'product'], axis=1)\n",
    "features_1 = df_1.drop(['id', 'product'], axis=1)\n",
    "features_2 = df_2.drop(['id', 'product'], axis=1)\n",
    "\n",
    "targets = df['product']\n",
    "targets_1 = df_1['product']\n",
    "targets_2 = df_2['product']\n",
    "\n",
    "# Splitting the dataset into training and validation sets\n",
    "\n",
    "features_train, features_valid, targets_train, targets_valid = train_test_split(features, targets, test_size=0.25, random_state=12345)\n",
    "features_train, features_valid_1, targets_train_1, targets_valid_1 = train_test_split(features_1, targets_1, test_size=0.25, random_state=12345)\n",
    "features_train, features_valid_2, targets_train_2, targets_valid_2 = train_test_split(features_2, targets_2, test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_Petro(features, targets, features_valid, targets_valid):\n",
    "    # Initialize and train the linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(features, targets)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    predictions = model.predict(features_valid)\n",
    "\n",
    "    # Calculate the mean of the predictions\n",
    "    mean_pred = np.mean(predictions)\n",
    "    \n",
    "    # Calculate the RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(targets_valid, predictions))\n",
    "    \n",
    "    # Print the results\n",
    "    print('The mean of the predictions is:', mean_pred)\n",
    "    print('The RMSE of the model is:', rmse)\n",
    "    \n",
    "    return mean_pred, rmse, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the predictions is: 92.46564781325566\n",
      "The RMSE of the model is: 37.57547919032473\n"
     ]
    }
   ],
   "source": [
    "mean_pred, rmse, predictions = Model_Petro(features, targets, features_valid, targets_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the predictions is: 68.72718652381815\n",
      "The RMSE of the model is: 0.8930685055287837\n"
     ]
    }
   ],
   "source": [
    "mean_pred_1, rmse_1, predictions_1 = Model_Petro(features_1, targets_1, features_valid_1, targets_valid_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the predictions is: 94.94513027263157\n",
      "The RMSE of the model is: 40.026749644748875\n"
     ]
    }
   ],
   "source": [
    "mean_pred_2, rmse_2, predictions_2 = Model_Petro(features_2, targets_2, features_valid_2, targets_valid_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results presented so far, it can be said that the region with the best average is region 3. However, region 2 shows the highest precision in its results. Nonetheless, it is still too early to make general judgments for decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profit Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We define the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profitability(mean_pred, invest=100_000_000, wells=200, product_price=4500):\n",
    "    # Correctly calculate the unit price\n",
    "    unit_price = invest / (wells * product_price)\n",
    "    \n",
    "    # Calculate the threshold\n",
    "    threshold = invest / (wells * product_price)\n",
    "    \n",
    "    if mean_pred >= threshold:\n",
    "        print('The average amount of reserves will generate profits.')\n",
    "    else:\n",
    "        print('The average amount of reserves will result in losses.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation by regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average amount of reserves will result in losses.\n",
      "The average amount of reserves will result in losses.\n",
      "The average amount of reserves will result in losses.\n"
     ]
    }
   ],
   "source": [
    "profitability(mean_pred) # Estimations for region 1\n",
    "profitability(mean_pred_1) # Estimations for region 2\n",
    "profitability(mean_pred_2) # Estimations for region 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were to randomly select 200 wells in each of the regions, we would incur losses that would make the project unfeasible. Therefore, we need another method to select the best exploitation sites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risks and Profits by Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top(predictions, targets):\n",
    "    data = pd.DataFrame({'predictions': predictions, 'targets': targets})\n",
    "    top_200 = data.nlargest(200, 'predictions')\n",
    "    return top_200\n",
    "\n",
    "def calculate(top):\n",
    "    revenue = 500000 / 111.1\n",
    "    total_revenue = top['targets'].sum() * revenue\n",
    "    investment = 100000000\n",
    "    profit = total_revenue - investment\n",
    "    return profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_200_1 = top(predictions, targets_valid)\n",
    "profit_1 = calculate(top_200_1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_200_2 = top(predictions_1, targets_valid_1)\n",
    "profit_2 = calculate(top_200_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_200_3 = top(predictions_2, targets_valid_2)\n",
    "profit_3 = calculate(top_200_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential results for region 0 USD: 33221582.589657485\n",
      "Potential results for region 1 USD: 24163283.295144632\n",
      "Potential results for region 2 USD: 27336645.095843896\n"
     ]
    }
   ],
   "source": [
    "# Print potential profits\n",
    "print('Potential results for region 0 USD:', profit_1)\n",
    "print('Potential results for region 1 USD:', profit_2)\n",
    "print('Potential results for region 2 USD:', profit_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we select the 200 best wells per region, our results improve significantly. We could have profits, and these could be highly profitable by selecting region 0, which has the best profit margin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of Risks and Profits for Each Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_200(predictions, targets):\n",
    "    # Convert to numpy arrays\n",
    "    targets = np.asarray(targets)\n",
    "    predictions = np.asarray(predictions)\n",
    "    \n",
    "    sorted = np.argsort(predictions)[::-1]  # Sort predictions in descending order\n",
    "    top_200_indices = sorted[:200]  # Get the indices of the top 200 predictions\n",
    "    selected_predictions = predictions[top_200_indices]  # Select the top 200 predictions\n",
    "    selected_targets = targets[top_200_indices]  # Select the corresponding targets for the top 200 predictions\n",
    "    \n",
    "    return selected_predictions, selected_targets  \n",
    "\n",
    "def bootstrap_profit(predictions, targets, n_iterations=1000, sample_size=500, investment_cost=100000000, revenue_per_unit=4500):\n",
    "    state = np.random.RandomState(12345)\n",
    "    profits = []\n",
    "    for i in range(n_iterations):\n",
    "        # Take a bootstrap sample of predictions and targets\n",
    "        sample_predictions, sample_targets = resample(predictions, targets, n_samples=sample_size, random_state=state)\n",
    "        \n",
    "        # Select the top 200 wells from the samples\n",
    "        _, sample_top_targets = top_200(sample_predictions, sample_targets)\n",
    "        \n",
    "        # Calculate the total revenue for this sample\n",
    "        total_revenue = sample_top_targets.sum() * revenue_per_unit\n",
    "        profit = total_revenue - investment_cost  # Calculate profit\n",
    "        profits.append(profit)\n",
    "    \n",
    "    # Convert profits to a numpy array\n",
    "    profits = np.array(profits)\n",
    "    \n",
    "    # Calculate the average profit\n",
    "    avg_profit = profits.mean()\n",
    "    \n",
    "    # Calculate the 95% confidence interval\n",
    "    conf_interval = np.percentile(profits, [2.5, 97.5])\n",
    "    \n",
    "    # Calculate the risk of loss (negative profit)\n",
    "    risk_of_loss = (profits < 0).mean() * 100  # As a percentage\n",
    "    \n",
    "    return avg_profit, conf_interval, risk_of_loss\n",
    "\n",
    "# Using the functions\n",
    "avg_profit, conf_interval, risk_of_loss = bootstrap_profit(predictions, targets_valid)\n",
    "avg_profit_1, conf_interval_1, risk_of_loss_1 = bootstrap_profit(predictions_1, targets_valid_1)\n",
    "avg_profit_2, conf_interval_2, risk_of_loss_2 = bootstrap_profit(predictions_2, targets_valid_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region 0: Average profit = 3964927.666096237 , 95% CI = [-1088816.18926101  9138435.96291906] , Risk of loss = 6.4 %\n",
      "Region 1: Average profit = 4560451.057866608 , 95% CI = [ 338205.09398985 8522894.53866035] , Risk of loss = 1.5 %\n",
      "Region 2: Average profit = 4053867.734904668 , 95% CI = [-1680474.36516634  9519024.87781419] , Risk of loss = 7.8 %\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "print(\"Region 0: Average profit =\", avg_profit, \", 95% CI =\", conf_interval, \", Risk of loss =\", risk_of_loss, \"%\")\n",
    "print(\"Region 1: Average profit =\", avg_profit_1, \", 95% CI =\", conf_interval_1, \", Risk of loss =\", risk_of_loss_1, \"%\")\n",
    "print(\"Region 2: Average profit =\", avg_profit_2, \", 95% CI =\", conf_interval_2, \", Risk of loss =\", risk_of_loss_2, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything seems to indicate that Region 1 has the highest profit margin and a significantly lower percentage of losses, with only 1.5%. However, due to the high risk of 7.8% and the estimated profits being not as significant compared to other regions, it is recommended to dismiss Region 2 for exploitation. Instead, it is advised to focus on Region 1, followed by Region 0, as they present lower risks and better potential profits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- The datasets are complete and do not require data completion, data conversion, or removal of null values, making the results highly reliable.\n",
    "- The linear regression technique provided acceptable validation values for the normal progression of the research.\n",
    "- The two best exploitation areas with the highest values were estimated, and the region that could lead to losses in the case of eventual exploitation was discarded."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 11,
    "start_time": "2024-09-08T14:17:04.138Z"
   },
   {
    "duration": 4,
    "start_time": "2024-09-08T14:18:11.979Z"
   },
   {
    "duration": 3,
    "start_time": "2024-09-08T14:18:18.092Z"
   },
   {
    "duration": 152,
    "start_time": "2024-09-08T14:30:30.097Z"
   },
   {
    "duration": 776,
    "start_time": "2024-09-08T14:30:36.529Z"
   },
   {
    "duration": 354,
    "start_time": "2024-09-08T14:30:37.308Z"
   },
   {
    "duration": 28,
    "start_time": "2024-09-08T14:30:37.664Z"
   },
   {
    "duration": 217,
    "start_time": "2024-09-08T14:30:37.695Z"
   },
   {
    "duration": 0,
    "start_time": "2024-09-08T14:30:37.914Z"
   },
   {
    "duration": 0,
    "start_time": "2024-09-08T14:30:37.915Z"
   },
   {
    "duration": 0,
    "start_time": "2024-09-08T14:30:37.916Z"
   },
   {
    "duration": 0,
    "start_time": "2024-09-08T14:30:37.917Z"
   },
   {
    "duration": 0,
    "start_time": "2024-09-08T14:30:37.918Z"
   },
   {
    "duration": 0,
    "start_time": "2024-09-08T14:30:37.919Z"
   },
   {
    "duration": 0,
    "start_time": "2024-09-08T14:30:37.920Z"
   },
   {
    "duration": 0,
    "start_time": "2024-09-08T14:30:37.921Z"
   },
   {
    "duration": 0,
    "start_time": "2024-09-08T14:30:37.921Z"
   },
   {
    "duration": 0,
    "start_time": "2024-09-08T14:30:37.922Z"
   },
   {
    "duration": 0,
    "start_time": "2024-09-08T14:30:37.923Z"
   },
   {
    "duration": 0,
    "start_time": "2024-09-08T14:30:37.924Z"
   },
   {
    "duration": 0,
    "start_time": "2024-09-08T14:30:37.925Z"
   },
   {
    "duration": 0,
    "start_time": "2024-09-08T14:30:37.926Z"
   },
   {
    "duration": 0,
    "start_time": "2024-09-08T14:30:37.928Z"
   },
   {
    "duration": 785,
    "start_time": "2024-09-08T14:32:13.123Z"
   },
   {
    "duration": 216,
    "start_time": "2024-09-08T14:32:13.910Z"
   },
   {
    "duration": 31,
    "start_time": "2024-09-08T14:32:14.129Z"
   },
   {
    "duration": 21,
    "start_time": "2024-09-08T14:32:14.163Z"
   },
   {
    "duration": 42,
    "start_time": "2024-09-08T14:32:14.187Z"
   },
   {
    "duration": 30,
    "start_time": "2024-09-08T14:32:14.230Z"
   },
   {
    "duration": 3,
    "start_time": "2024-09-08T14:32:14.264Z"
   },
   {
    "duration": 38,
    "start_time": "2024-09-08T14:32:14.269Z"
   },
   {
    "duration": 12,
    "start_time": "2024-09-08T14:32:14.308Z"
   },
   {
    "duration": 86,
    "start_time": "2024-09-08T14:32:14.323Z"
   },
   {
    "duration": 3,
    "start_time": "2024-09-08T14:32:14.412Z"
   },
   {
    "duration": 3,
    "start_time": "2024-09-08T14:32:14.417Z"
   },
   {
    "duration": 3,
    "start_time": "2024-09-08T14:32:14.422Z"
   },
   {
    "duration": 299,
    "start_time": "2024-09-08T14:32:14.427Z"
   },
   {
    "duration": 0,
    "start_time": "2024-09-08T14:32:14.728Z"
   },
   {
    "duration": 0,
    "start_time": "2024-09-08T14:32:14.729Z"
   },
   {
    "duration": 0,
    "start_time": "2024-09-08T14:32:14.730Z"
   },
   {
    "duration": 0,
    "start_time": "2024-09-08T14:32:14.731Z"
   },
   {
    "duration": 0,
    "start_time": "2024-09-08T14:32:14.732Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-08T14:32:37.784Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-08T14:32:39.261Z"
   },
   {
    "duration": 15,
    "start_time": "2024-09-08T14:32:39.412Z"
   },
   {
    "duration": 13,
    "start_time": "2024-09-08T14:32:39.563Z"
   },
   {
    "duration": 12,
    "start_time": "2024-09-08T14:32:39.677Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-08T14:32:48.754Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-08T14:32:48.897Z"
   },
   {
    "duration": 3,
    "start_time": "2024-09-08T14:32:49.057Z"
   },
   {
    "duration": 529,
    "start_time": "2024-09-08T14:32:51.264Z"
   },
   {
    "duration": 11,
    "start_time": "2024-09-08T14:32:51.795Z"
   }
  ],
  "kernelspec": {
   "display_name": "entorno",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
